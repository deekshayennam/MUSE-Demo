{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About Me\n",
    "\n",
    "Deeksha Yennam - Senior Data Scientist at Walmart\n",
    "\n",
    "Masters degree in Business Analytics from UT Austin with 3 years of industry experience in Data Science\n",
    "\n",
    "Find me at : https://www.linkedin.com/in/deeksha-yennam/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilingual Unviersal Sentence Encoder (MUSE)\n",
    "\n",
    "## What is it?\n",
    "\n",
    "* Multilingual document embedding model that converts text into a 512 dimension vector representation\n",
    "\n",
    "## Salient Features\n",
    "\n",
    "* Works with as many as 16 languages. Model is language-agnostic, meaning language of the text does not have to be specified to the model\n",
    "\n",
    "* Optimized for multi-word text like sentences and paragraphs. \n",
    "\n",
    "## How to use it?\n",
    "\n",
    "* The pre-trained model is available for use as a module on tensorflow-hub. \n",
    "* See the below code example for a simple demo\n",
    "\n",
    "## Limitations\n",
    "\n",
    "* The model size is pretty large. Inference can be time-consuming when running on a large dataset. Recommend using the input pipeline from tensorflow (tf.data) and leveraging batching when running the model on large datasets\n",
    "\n",
    "\n",
    "## Resources\n",
    "* https://tfhub.dev/google/universal-sentence-encoder-multilingual/3\n",
    "* https://arxiv.org/abs/1907.04307\n",
    "* https://ai.googleblog.com/2019/07/multilingual-universal-sentence-encoder.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo with English Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T18:59:27.260832Z",
     "start_time": "2020-07-16T18:59:27.258368Z"
    }
   },
   "outputs": [],
   "source": [
    "## Example Data\n",
    "sentences = [\"I have a dog\",\"I would love to have a pet\",\"I live in a big city\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T18:59:32.461401Z",
     "start_time": "2020-07-16T18:59:29.777943Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the model\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import tensorflow_text\n",
    "\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-multilingual/3\"\n",
    "embed = hub.load(module_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T18:59:33.557437Z",
     "start_time": "2020-07-16T18:59:32.463166Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute embeddings for our sample data\n",
    "embeddings = embed(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T18:59:33.564431Z",
     "start_time": "2020-07-16T18:59:33.559719Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 512), dtype=float32, numpy=\n",
       "array([[ 0.06540088, -0.03345164,  0.03330484, ..., -0.02112507,\n",
       "         0.04501928, -0.02898191],\n",
       "       [ 0.02742887, -0.01307626, -0.01204817, ..., -0.01096772,\n",
       "         0.01694283,  0.09336831],\n",
       "       [ 0.05165894, -0.05038729, -0.0263377 , ..., -0.07095326,\n",
       "         0.01125661, -0.06504603]], dtype=float32)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T18:31:02.205172Z",
     "start_time": "2020-07-16T18:31:02.200244Z"
    }
   },
   "source": [
    "### Use embeddings to compute sentence similarity scores\n",
    "Embeddings returned by MUSE are approximately normalized, hence the cosine similarity of two sentences can be approximated as the dot product of their embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T18:59:42.067509Z",
     "start_time": "2020-07-16T18:59:42.062071Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity score between \"I have a dog\" and \"I would love to have a pet\" is 0.6374889016151428\n",
      "Similarity score between \"I have a dog\" and \"I live in a big city\" is 0.34745800495147705\n",
      "Similarity score between \"I would love to have a pet\" and \"I live in a big city\" is 0.26571404933929443\n"
     ]
    }
   ],
   "source": [
    "print(f\"Similarity score between \\\"{sentences[0]}\\\" and \\\"{sentences[1]}\\\" is {np.dot(embeddings[0],embeddings[1])}\")\n",
    "print(f\"Similarity score between \\\"{sentences[0]}\\\" and \\\"{sentences[2]}\\\" is {np.dot(embeddings[0],embeddings[2])}\")\n",
    "print(f\"Similarity score between \\\"{sentences[1]}\\\" and \\\"{sentences[2]}\\\" is {np.dot(embeddings[1],embeddings[2])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo with multilingual data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see what happens when our input data is in multiple languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T19:00:10.979299Z",
     "start_time": "2020-07-16T19:00:10.976523Z"
    }
   },
   "outputs": [],
   "source": [
    "sentences_2 = [\"tengo un perro\", \"J'aimerais avoir un animal de compagnie\", \"Vivo in una grande citt√†\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T19:00:12.552356Z",
     "start_time": "2020-07-16T19:00:12.539651Z"
    }
   },
   "outputs": [],
   "source": [
    "embeddings_2 = embed(sentences_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine similarity scores between sentences in different languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T19:00:14.536539Z",
     "start_time": "2020-07-16T19:00:14.531470Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between \"I have a dog\" and its direct translation into Spanish is 0.922921895980835\n",
      "Similarity between \"I would love to have a pet\" and its direct translation into French is 0.8489859700202942\n",
      "Similarity between \"I live in a big city\" and its direct translation into Italian is 0.9239956140518188\n"
     ]
    }
   ],
   "source": [
    "# Similarity scores for direct translations \n",
    "print(f\"Similarity between \\\"{sentences[0]}\\\" and its direct translation into Spanish is {np.dot(embeddings[0],embeddings_2[0])}\")\n",
    "print(f\"Similarity between \\\"{sentences[1]}\\\" and its direct translation into French is {np.dot(embeddings[1],embeddings_2[1])}\")\n",
    "print(f\"Similarity between \\\"{sentences[2]}\\\" and its direct translation into Italian is {np.dot(embeddings[2],embeddings_2[2])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T19:00:23.852386Z",
     "start_time": "2020-07-16T19:00:23.846680Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity score between \"I have a dog\" and \"I would love to have a pet\" is 0.6374889016151428\n",
      "Similarity score between \"I have a dog\" and \"J'aimerais avoir un animal de compagnie\" is 0.5772875547409058\n",
      "Similarity score between \"tengo un perro\" and \"J'aimerais avoir un animal de compagnie\" is 0.5664279460906982\n"
     ]
    }
   ],
   "source": [
    "# Similarity scores for different sentences written in different languages\n",
    "print(f\"Similarity score between \\\"{sentences[0]}\\\" and \\\"{sentences[1]}\\\" is {np.dot(embeddings[0],embeddings[1])}\")\n",
    "print(f\"Similarity score between \\\"{sentences[0]}\\\" and \\\"{sentences_2[1]}\\\" is {np.dot(embeddings[0],embeddings_2[1])}\")\n",
    "print(f\"Similarity score between \\\"{sentences_2[0]}\\\" and \\\"{sentences_2[1]}\\\" is {np.dot(embeddings_2[0],embeddings_2[1])}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}